{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3pcN6LhMcj0NSm2CuAwNT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anishgoswamicode/wikipedia-semantic-clustering/blob/main/wikipedia_semantic_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq4mWLqx1k9t"
      },
      "outputs": [],
      "source": [
        "!pip install -q wikipedia\n",
        "!pip install -q sentence-transformers umap-learn keybert\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia\n",
        "import random\n",
        "\n",
        "# Choose categories to pull summaries from\n",
        "topics = [\"Artificial intelligence\", \"Philosophy\", \"Genetics\", \"Climate change\", \"World War II\", \"Blockchain\", \"Economics\", \"Quantum mechanics\", \"Indian History\", \"Linguistics\"]\n",
        "\n",
        "summaries = []\n",
        "labels = []\n",
        "\n",
        "for topic in topics:\n",
        "    try:\n",
        "        related_pages = wikipedia.search(topic, results=100)\n",
        "        for title in related_pages:\n",
        "            try:\n",
        "                summary = wikipedia.summary(title)\n",
        "                summaries.append(summary)\n",
        "                labels.append(topic)\n",
        "            except Exception:\n",
        "                continue\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "print(f\"Total articles collected: {len(summaries)}\")\n"
      ],
      "metadata": {
        "id": "rcTPQ84d2EgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(summaries, show_progress_bar=True)\n"
      ],
      "metadata": {
        "id": "jFDo8n-p2IyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap.umap_ as umap\n",
        "\n",
        "reducer = umap.UMAP(n_neighbors=10, min_dist=0.1, metric='cosine', random_state=42)\n",
        "embedding_2d = reducer.fit_transform(embeddings)\n"
      ],
      "metadata": {
        "id": "kTyjl_Q12N4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=3)\n",
        "cluster_labels = dbscan.fit_predict(embedding_2d)\n",
        "\n",
        "print(f\"Clusters found: {len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)}\")\n"
      ],
      "metadata": {
        "id": "yaVL41Jo2V0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=cluster_labels, cmap='tab20', s=40)\n",
        "plt.title(\"Topic Topology of Wikipedia Summaries\")\n",
        "plt.xlabel(\"UMAP-1\")\n",
        "plt.ylabel(\"UMAP-2\")\n",
        "plt.colorbar(label=\"Cluster ID\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iha95DOL2hMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assume:\n",
        "# - embedding_2d is your UMAP result (shape: [N, 2])\n",
        "# - cluster_labels is your DBSCAN result (shape: [N])\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Scatter plot\n",
        "scatter = plt.scatter(\n",
        "    embedding_2d[:, 0],\n",
        "    embedding_2d[:, 1],\n",
        "    c=cluster_labels,\n",
        "    cmap='tab20',\n",
        "    s=20,\n",
        "    alpha=0.8\n",
        ")\n",
        "\n",
        "# Plot title and labels\n",
        "plt.title(\"UMAP + DBSCAN Clustered Wikipedia Topics\")\n",
        "plt.xlabel(\"UMAP-1\")\n",
        "plt.ylabel(\"UMAP-2\")\n",
        "\n",
        "# Label each cluster with its number at the median location\n",
        "unique_clusters = np.unique(cluster_labels)\n",
        "for cluster_id in unique_clusters:\n",
        "    if cluster_id == -1:\n",
        "        continue  # skip noise\n",
        "\n",
        "    # Find the points in this cluster\n",
        "    cluster_points = embedding_2d[cluster_labels == cluster_id]\n",
        "\n",
        "    # Compute median position\n",
        "    median_x, median_y = np.median(cluster_points, axis=0)\n",
        "\n",
        "    # Plot cluster label at median\n",
        "    plt.text(median_x, median_y, f\"Cluster {cluster_id}\", fontsize=12,\n",
        "             bbox=dict(facecolor='white', alpha=0.7), ha='center')\n",
        "\n",
        "plt.colorbar(scatter, label=\"Cluster ID\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "weQn_EIL8ljt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "from collections import defaultdict\n",
        "\n",
        "kw_model = KeyBERT(model)\n",
        "\n",
        "cluster_to_summaries = defaultdict(list)\n",
        "for i, label in enumerate(cluster_labels):\n",
        "    if label == -1:\n",
        "        continue  # skip noise\n",
        "    cluster_to_summaries[label].append(summaries[i])\n",
        "\n",
        "# Print top keywords for each cluster\n",
        "for cluster_id, cluster_texts in cluster_to_summaries.items():\n",
        "    joined = \" \".join(cluster_texts[:10])\n",
        "    keywords = kw_model.extract_keywords(joined, top_n=5)\n",
        "    print(f\"\\nðŸ”¹ Cluster {cluster_id}:\")\n",
        "    for kw in keywords:\n",
        "        print(f\" - {kw[0]} ({kw[1]:.2f})\")\n"
      ],
      "metadata": {
        "id": "vC92Bujf2qJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}